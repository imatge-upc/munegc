---
title: "introduction"
bg: blue
color: white
fa-icon: quote-left
---
<div style="text-align: justify">
Multi-modal fusion has been proved to help enhance the performance of scene classification tasks. This paper presents a 2D-3D Fusion stage that combines 3D Geometric Features with 2D Texture Features obtained by 2D Convolutional Neural Networks. To get a robust 3D Geometric embedding, a network that uses two novel layers is proposed. The first layer, Multi-Neighbourhood Graph Convolution, aims to learn a more robust geometric descriptor of the scene combining two different neighbourhoods: one in the Euclidean space and the other in the Feature space. The second proposed layer, Nearest Voxel Pooling, improves the performance of the well-known Voxel Pooling. Experimental results, using NYU-Depth-V2 and SUN RGB-D datasets, show that the proposed method outperforms the current state-of-the-art in RGB-D indoor scene classification task. 
</div>
If you find this work useful, please consider citing:

<div class="highlight">
	<pre class="highlight">
	<code>Albert Mosella-Montoro, Javier Ruiz-Hidalgo, 2D-3D Geometric Fusion network using Multi-Neighbourhood Graph Convolution for RGB-D indoor scene classification, Information Fusion, 2021, ISSN 1566-2535, https://doi.org/10.1016/j.inffus.2021.05.002</code>
	</pre>
</div>

<pre style="overflow:auto"> 
@article{MOSELLAMONTORO2021,
         title = {2D-3D Geometric Fusion network using Multi-Neighbourhood Graph Convolution for RGB-D indoor scene classification},
         journal = {Information Fusion},
         year = {2021},
         issn = {1566-2535},
         doi = {https://doi.org/10.1016/j.inffus.2021.05.002},
         url = {https://www.sciencedirect.com/science/article/pii/S1566253521001032},
         author = {Albert Mosella-Montoro and Javier Ruiz-Hidalgo},
}
</pre>



Check our paper [here](https://www.sciencedirect.com/science/article/pii/S1566253521001032).
